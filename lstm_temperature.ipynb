{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55342526-f62e-41c2-b110-9b75283c993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install codecarbon scikit-learn torch matplotlib pandas numpy tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from codecarbon import EmissionsTracker\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b966186a-78ed-493b-854b-e052ab1c516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Interpolado_jacarepagua.csv', sep=',', encoding='latin-1')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb56827-2847-49c2-966c-f1f242546f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "df['year'] = df['datetime'].dt.year\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['day'] = df['datetime'].dt.day\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['minute'] = df['datetime'].dt.minute\n",
    "df['second'] = df['datetime'].dt.second\n",
    "\n",
    "input_data = df.drop([\n",
    "    'datetime',\n",
    "       'TEMPERATURA DO PONTO DE ORVALHO (°C)',\n",
    "       'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)',\n",
    "       'TEMPERATURA MÍNIMA NA HORA ANT. (AUT) (°C)',\n",
    "       'TEMPERATURA ORVALHO MAX. NA HORA ANT. (AUT) (°C)',\n",
    "       'TEMPERATURA ORVALHO MIN. NA HORA ANT. (AUT) (°C)'], axis=1)\n",
    "targets = df['TEMPERATURA DO AR - BULBO SECO, HORARIA (°C)'].values\n",
    "T = 20                   \n",
    "D = input_data.shape[1] \n",
    "N = len(input_data) - T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb68eced-9b2d-41ee-8726-56d34a116bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train size: 80% of the total data size\n",
    "train_size = int(len(input_data) * 0.80)\n",
    "\n",
    "# Normalization of the inputs\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(input_data[:train_size + T - 1])\n",
    "input_data = scaler.transform(input_data)\n",
    "\n",
    "# Preparing X_train and y_train\n",
    "X_train = np.zeros((train_size, T, D))\n",
    "y_train = np.zeros((train_size, 1))\n",
    "\n",
    "for t in range(train_size):\n",
    "  X_train[t, :, :] = input_data[t:t+T]\n",
    "  y_train[t] = (targets[t+T])\n",
    "\n",
    "# Preparing X_test and y_test\n",
    "X_test = np.zeros((N - train_size, T, D))\n",
    "y_test = np.zeros((N - train_size, 1))\n",
    "\n",
    "for i in range(N - train_size):\n",
    "  t = i + train_size\n",
    "  X_test[i, :, :] = input_data[t:t+T]\n",
    "  y_test[i] = (targets[t+T])\n",
    "\n",
    "# Make inputs and targets\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ab9d7e-05d1-4ff8-adc1-30e6eb9c1c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "    super(LSTM, self).__init__()\n",
    "    self.M = hidden_dim\n",
    "    self.L = layer_dim\n",
    "\n",
    "    self.rnn = nn.LSTM(\n",
    "        input_size=input_dim,\n",
    "        hidden_size=hidden_dim,\n",
    "        num_layers=layer_dim,\n",
    "        batch_first=True)\n",
    "    #batch_first to have (batch_dim, seq_dim, feature_dim)\n",
    "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "  def forward(self, X):\n",
    "    # initial hidden state and cell state\n",
    "    h0 = torch.zeros(self.L, X.size(0), self.M).to(\"cpu\")\n",
    "    c0 = torch.zeros(self.L, X.size(0), self.M).to(\"cpu\")\n",
    "\n",
    "    out, (hn, cn) = self.rnn(X, (h0.detach(), c0.detach()))\n",
    "\n",
    "    # h(T) at the final time step\n",
    "    out = self.fc(out[:, -1, :])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f2aab-d3cf-43b8-bbbe-c94e992da895",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_dim=D, hidden_dim=256, layer_dim=2, output_dim=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b960f-ea00-437c-b58f-36c4aec61152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, learning_rate, X_train, y_train, X_test, y_test, epochs=100, batch_size=32):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] — Train Loss: {epoch_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ede5f-f285-4144-a0c8-09a9c17b0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_rmse(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "\n",
    "    y_true_np = y_test.cpu().numpy().flatten()\n",
    "    y_pred_np = y_pred.cpu().numpy().flatten()\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_np, y_pred_np))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f8a79f-ed6f-4075-8883-453f7bb87bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = EmissionsTracker(\n",
    "    project_name=\"TEMPERATURE lstm\",\n",
    "    output_file='codecarbon-lstm/codecarbon_emissions_temp.csv',\n",
    "    log_level = \"critical\"\n",
    ")\n",
    "\n",
    "tracker.start()\n",
    "\n",
    "train_losses, test_losses = train(\n",
    "    model,\n",
    "    learning_rate=0.001,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    epochs=25,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "emissions: float = tracker.stop()\n",
    "print(f\"emissions={emissions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02645016-8e8a-4c6c-90e5-4f7eb4a398b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dispersion(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device  # Get the model's device (CPU or CUDA)\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "\n",
    "    # Convert tensors to NumPy arrays for plotting\n",
    "    y_true_np = y_test.cpu().numpy()\n",
    "    y_pred_np = y_pred.cpu().numpy()\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(y_true_np, y_pred_np, alpha=0.7, color='blue')\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title('Dispersion Plot: True vs Predicted')\n",
    "    plt.grid(True)\n",
    "    plt.plot([y_true_np.min(), y_true_np.max()], [y_true_np.min(), y_true_np.max()], 'r--')  # Ideal line\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./lstm_emissions/dispersao_temp.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da3dde-c674-4da4-b8e1-c05e0a602c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dispersion(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9041b2aa-adfc-4596-b49f-48111fd4b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_real_vs_predicted(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device \n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "\n",
    "    y_true_np = y_test.cpu().numpy().flatten()\n",
    "    y_pred_np = y_pred.cpu().numpy().flatten()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_true_np, label='Real', linewidth=2)\n",
    "    plt.plot(y_pred_np, label='Predicted', linewidth=2)\n",
    "    plt.title('Real vs Predicted Values')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3432cba8-0686-453e-aeb3-3e5bc7aeb6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_real_vs_predicted(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a363167d-871d-45ef-908c-7e135bf25999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rmse(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "\n",
    "    y_true_np = y_test.cpu().numpy().flatten()\n",
    "    y_pred_np = y_pred.cpu().numpy().flatten()\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_np, y_pred_np))\n",
    "    print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14d3447-e61c-4006-8b8d-52449af5a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_rmse(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be9c1d1-de6c-4f5e-8af6-3b5b2bd710e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lstm_prediction_over_time(model, X_test, y_test, timestamps, start_date=None, end_date=None, save=False):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "\n",
    "    y_true_np = y_test.cpu().numpy().flatten()\n",
    "    y_pred_np = y_pred.cpu().numpy().flatten()\n",
    "    timestamps = pd.to_datetime(timestamp)\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        'Timestamp': timestamps,\n",
    "        'Actual': y_true_np,\n",
    "        'Predicted': y_pred_np\n",
    "    })\n",
    "\n",
    "    if start_date:\n",
    "        data = data[data['Timestamp'] >= pd.to_datetime(start_date)]\n",
    "    if end_date:\n",
    "        data = data[data['Timestamp'] <= pd.to_datetime(end_date)]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(data['Timestamp'], data['Actual'], label='Actual Values', color='blue', linewidth=2)\n",
    "    plt.plot(data['Timestamp'], data['Predicted'], label='Predicted Values', color='orange', linewidth=2)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('LSTM: Actual vs. Predicted Values Over Time')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(save)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9597e7e-8f55-402a-b719-eba2a3a81c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2023-01-01\"\n",
    "end_date = \"2023-01-30\"\n",
    "\n",
    "timestamps = pd.to_datetime(df['timestamp'])\n",
    "timestamps_for_plot = timestamps[T:T + N]\n",
    "timestamps_test = timestamps_for_plot[train_size:]\n",
    "\n",
    "plot_lstm_prediction_over_time(model, X_test, y_test, timestamps_test,start_date, end_date, save='./lstm_images/lstm_temp_rvp.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
